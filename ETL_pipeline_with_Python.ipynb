{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL pipeline with Python.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMesIc0NhSnXp0l1J0ocmES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zewang001/Data-Engineering/blob/main/ETL_pipeline_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ETL pipeline with Python**"
      ],
      "metadata": {
        "id": "9-PZxf_PQq8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "common\n",
        "\n",
        "> \\base.py   Initialize database connection and session\n",
        "---\n",
        ">\\tables.py   Python classes for database table\n",
        "---\n",
        ">\\create_table.py   Create tables\n",
        "---\n",
        "execute.py   Call all the main functions\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "extract.py   Extract .zip from source url\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "transform.py   Data cleaning, data transforming\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "load.py   Load data into database\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "create_insights.py   create view for insights\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "insights_export.py   export insights from view to excel"
      ],
      "metadata": {
        "id": "LsN2nOlUonoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **common\\base.py**"
      ],
      "metadata": {
        "id": "vpvhSxVsSnK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common\\base.py\n",
        "# Import the modules required\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import Session, declarative_base\n",
        "\n",
        "# Create the engine\n",
        "engine = create_engine(\"postgresql+psycopg2://dcstudent:S3cretPassw0rd@localhost:5432/campdata-prod\")\n",
        "\n",
        "# Initialize the session\n",
        "session = Session(engine)\n",
        "\n",
        "# Initialize the declarative base\n",
        "Base = declarative_base()"
      ],
      "metadata": {
        "id": "4y-EeizWmRU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **common\\tables.py**"
      ],
      "metadata": {
        "id": "mEx5YA5lStA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common\\tables.py \n",
        "from sqlalchemy import Column, Integer, String, Date\n",
        "\n",
        "from sqlalchemy.orm import column_property\n",
        "from base import Base\n",
        "\n",
        "from sqlalchemy import cast\n",
        "\n",
        "\n",
        "class PprRawAll(Base):\n",
        "    __tablename__ = \"ppr_raw_all\"\n",
        "\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    date_of_sale = Column(String(55))\n",
        "    address = Column(String(255))\n",
        "    postal_code = Column(String(55))\n",
        "    county = Column(String(55))\n",
        "    price = Column(String(55))\n",
        "    description = Column(String(255))\n",
        "    transaction_id = column_property(\n",
        "        date_of_sale + \"_\" + address + \"_\" + county + \"_\" + price)\n",
        "\n",
        "\n",
        "class PprCleanAll(Base):\n",
        "    __tablename__ = \"ppr_clean_all\"\n",
        "\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    # Create a new column of type Date\n",
        "    date_of_sale = Column(Date)\n",
        "    address = Column(String(255))\n",
        "    postal_code = Column(String(55))\n",
        "    county = Column(String(55))\n",
        "    price = Column(Integer)\n",
        "    description = Column(String(255))\n",
        "    transaction_id = column_property(\n",
        "        cast(date_of_sale, String) + \"_\" + address + \"_\" + county + \"_\" + cast(price, String)\n",
        "    )"
      ],
      "metadata": {
        "id": "Fm54erTOrorf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **common\\create_tables.py**"
      ],
      "metadata": {
        "id": "0Zj2zW8ySzER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common\\create_tables.py\n",
        "from base import Base, engine\n",
        "# Import the PprRawAll table\n",
        "from tables import PprRawAll, PprCleanAll\n",
        "\n",
        "# Create the table in the database\n",
        "if __name__ == \"__main__\":\n",
        "    Base.metadata.create_all(engine)"
      ],
      "metadata": {
        "id": "_MP0k9Rv6Uxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **execute.py**"
      ],
      "metadata": {
        "id": "A8KFSjM_UUDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#execute.py\n",
        "import extract\n",
        "import transform\n",
        "import load\n",
        "\n",
        "# Call its main function\n",
        "if __name__ == \"__main__\":\n",
        "    extract.main()\n",
        "    transform.main()  \n",
        "    load.main()"
      ],
      "metadata": {
        "id": "V6k6P1kMUUDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **extract.py**"
      ],
      "metadata": {
        "id": "ScWmONTmUH9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract.py\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import tempfile\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import requests\n",
        "\n",
        "# Settings\n",
        "base_path = os.path.abspath(__file__ + \"/../../\")\n",
        "\n",
        "# START - Paths for new February 2021 data available\n",
        "\n",
        "# External website file url\n",
        "source_url = \"https://assets.datacamp.com/production/repositories/5899/datasets/66691278303f789ca4acd3c6406baa5fc6adaf28/PPR-ALL.zip\"\n",
        "\n",
        "# Source path where we want to save the .zip file downloaded from the website\n",
        "source_path = f\"{base_path}/data/source/downloaded_at=2021-02-01/PPR-ALL.zip\"\n",
        "\n",
        "# Raw path where we want to extract the new .csv data\n",
        "raw_path = f\"{base_path}/data/raw/downloaded_at=2021-02-01/ppr-all.csv\"\n",
        "\n",
        "# END - Paths for new February 2021 data available\n",
        "\n",
        "\n",
        "def create_folder_if_not_exists(path):\n",
        "    \"\"\"\n",
        "    Create a new folder if it doesn't exists\n",
        "    \"\"\"\n",
        "    # os.path.dirname() returns up to the directory path.\n",
        "    # In this case it is: f\"{base_path}/downloaded_at=2021-01-01\"\n",
        "    # \"ppr-all.zip\" is excluded\n",
        "\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "\n",
        "def download_snapshot():\n",
        "    \"\"\"\n",
        "    Download the new dataset from the source\n",
        "    \"\"\"\n",
        "    create_folder_if_not_exists(source_path)\n",
        "    # Open the .zip file in binary mode\n",
        "    with open(source_path, \"wb\") as source_ppr:\n",
        "        # 'verify=False' skips the verification the SSL certificate\n",
        "        response = requests.get(source_url, verify=False)\n",
        "        source_ppr.write(response.content)\n",
        "\n",
        "\n",
        "def save_new_raw_data():\n",
        "    \"\"\"\n",
        "    Save new raw data from the source\n",
        "    \"\"\"\n",
        "\n",
        "    create_folder_if_not_exists(raw_path)\n",
        "    with tempfile.TemporaryDirectory() as dirpath:\n",
        "        with ZipFile(\n",
        "            source_path,\n",
        "            \"r\",\n",
        "        ) as zipfile:\n",
        "            names_list = zipfile.namelist()\n",
        "            csv_file_path = zipfile.extract(names_list[0], path=dirpath)\n",
        "            # Open the CSV file in read mode\n",
        "            with open(csv_file_path, mode=\"r\", encoding=\"windows-1252\") as csv_file:\n",
        "                reader = csv.DictReader(csv_file)\n",
        "\n",
        "                row = next(reader)  # Get first row from reader\n",
        "                print(\"[Extract] First row example:\", row)\n",
        "\n",
        "                # Open the CSV file in write mode\n",
        "                with open(\n",
        "                    raw_path,\n",
        "                    mode=\"w\",\n",
        "                    encoding=\"windows-1252\"\n",
        "                ) as csv_file:\n",
        "                    # Rename field names so they're ready for the next step\n",
        "                    fieldnames = {\n",
        "                        \"Date of Sale (dd/mm/yyyy)\": \"date_of_sale\",\n",
        "                        \"Address\": \"address\",\n",
        "                        \"Postal Code\": \"postal_code\",\n",
        "                        \"County\": \"county\",\n",
        "                        \"Price (€)\": \"price\",\n",
        "                        \"Description of Property\": \"description\",\n",
        "                    }\n",
        "                    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "                    # Write headers as first line\n",
        "                    writer.writerow(fieldnames)\n",
        "                    for row in reader:\n",
        "                        # Write all rows in file\n",
        "                        writer.writerow(row)\n",
        "\n",
        "# Main function called inside the execute.py script\n",
        "def main():\n",
        "    print(\"[Extract] Start\")\n",
        "    print(\"[Extract] Downloading snapshot\")\n",
        "    download_snapshot\n",
        "    print(f\"[Extract] Saving data from '{source_path}' to '{raw_path}'\")\n",
        "    save_new_raw_data\n",
        "    print(f\"[Extract] End\")"
      ],
      "metadata": {
        "id": "faZNKew6UH9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **transform.py**"
      ],
      "metadata": {
        "id": "G_WyNgKBUmhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform.py\n",
        "# Import the submodule required\n",
        "from datetime import datetime\n",
        "\n",
        "def transform_case(input_string):\n",
        "    \"\"\"\n",
        "    Lowercase string fields\n",
        "    \"\"\"\n",
        "    # Return the string lowercase\n",
        "    return input_string.lower()\n",
        "  \n",
        "def update_date_of_sale(date_input):\n",
        "    \"\"\"\n",
        "    Update date format from DD/MM/YYYY to YYYY-MM-DD\n",
        "    \"\"\"\n",
        "    # Create a datetime object\n",
        "    current_format = datetime.strptime(date_input, \"%d/%m/%Y\")\n",
        "    # Convert to the expected date format\n",
        "    new_format = current_format.strftime(\"%Y-%m-%d\")\n",
        "    return new_format\n",
        "\n",
        "def update_price(price_input):\n",
        "    \"\"\"\n",
        "    Returns price as an integer by removing:\n",
        "    - \"€\" and \",\" symbol\n",
        "    - Converting to float first then to integer\n",
        "    \"\"\"\n",
        "    # Replace € with an empty string\n",
        "    price_input = price_input.replace(\"€\", \"\")\n",
        "    # Replace comma with an empty string\n",
        "    price_input = price_input.replace(\",\", \"\")\n",
        "    # Convert to float\n",
        "    price_input = float(price_input)\n",
        "    # Return price_input as integer\n",
        "    return int(price_input)\n",
        "  \n",
        "def update_description(description_input):\n",
        "    \"\"\"\n",
        "    Simplifies the description field for future analysis. Returns:\n",
        "    - \"new\" if string contains \"new\" substring\n",
        "    - \"second-hand\" if string contains \"second-hand\" substring\n",
        "    \"\"\"\n",
        "    description_input = transform_case(description_input)\n",
        "    # Check description and return \"new\" or \"second-hand\"\n",
        "    if \"new\" in description_input:\n",
        "        return \"new\"\n",
        "    elif \"second-hand\" in description_input:\n",
        "        return \"second-hand\"\n",
        "    return description_input\n",
        "\n",
        "def truncate_table():\n",
        "    \"\"\"\n",
        "    Ensure that \"ppr_raw_all\" table is always in empty state before running any transformations.\n",
        "    And primary key (id) restarts from 1.\n",
        "    \"\"\"\n",
        "    session.execute(\n",
        "        text(\"TRUNCATE TABLE ppr_raw_all;ALTER SEQUENCE ppr_raw_all_id_seq RESTART;\")\n",
        "    )\n",
        "    session.commit()\n",
        "\n",
        "\n",
        "def transform_new_data():\n",
        "    \"\"\"\n",
        "    Apply all transformations for each row in the .csv file before saving it into database\n",
        "    \"\"\"\n",
        "    with open(raw_path, mode=\"r\", encoding=\"windows-1252\") as csv_file:\n",
        "        # Read the new CSV snapshot ready to be processed\n",
        "        reader = csv.DictReader(csv_file)\n",
        "        # Initialize an empty list for our PprRawAll objects\n",
        "        ppr_raw_objects = []\n",
        "        for row in reader:\n",
        "            # Apply transformations and save as PprRawAll object\n",
        "            ppr_raw_objects.append(\n",
        "                PprRawAll(\n",
        "                    date_of_sale=update_date_of_sale(row[\"date_of_sale\"]),\n",
        "                    address=transform_case(row[\"address\"]),\n",
        "                    postal_code=transform_case(row[\"postal_code\"]),\n",
        "                    county=transform_case(row[\"county\"]),\n",
        "                    price=update_price(row[\"price\"]),\n",
        "                    description=update_description(row[\"description\"]),\n",
        "                )\n",
        "            )\n",
        "        # Save all new processed objects and commit\n",
        "        session.bulk_save_objects(ppr_raw_objects)\n",
        "        session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"[Transform] Start\")\n",
        "    print(\"[Transform] Remove any old data from ppr_raw_all table\")\n",
        "    truncate_table()\n",
        "    print(\"[Transform] Transform new data available in ppr_raw_all table\")\n",
        "    transform_new_data()\n",
        "    print(\"[Transform] End\")"
      ],
      "metadata": {
        "id": "xKcDgvEgxijK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **load.py**"
      ],
      "metadata": {
        "id": "10H3Ncisa4K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common.base import session\n",
        "from common.tables import PprRawAll, PprCleanAll\n",
        "\n",
        "from sqlalchemy import cast, Integer, Date\n",
        "from sqlalchemy.dialects.postgresql import insert\n",
        "\n",
        "\n",
        "def insert_transactions():\n",
        "    \"\"\"\n",
        "    Insert operation: add new data\n",
        "    \"\"\"\n",
        "    # Retrieve all the transaction ids from the clean table\n",
        "    clean_transaction_ids = session.query(PprCleanAll.transaction_id)\n",
        "\n",
        "    # date_of_sale and price needs to be casted as their\n",
        "    # datatype is not string but, respectively, Date and Integer\n",
        "    transactions_to_insert = session.query(\n",
        "        cast(PprRawAll.date_of_sale, Date),\n",
        "        PprRawAll.address,\n",
        "        PprRawAll.postal_code,\n",
        "        PprRawAll.county,\n",
        "        cast(PprRawAll.price, Integer),\n",
        "        PprRawAll.description,\n",
        "    ).filter(~PprRawAll.transaction_id.in_(clean_transaction_ids))\n",
        "\t\n",
        "    # Print total number of transactions to insert\n",
        "    print(\"Transactions to insert:\", transactions_to_insert.count())\n",
        "    \n",
        "    # Insert the rows from the previously selected transactions\n",
        "    stm = insert(PprCleanAll).from_select(\n",
        "        [\"date_of_sale\", \"address\", \"postal_code\", \"county\", \"price\", \"description\"],\n",
        "        transactions_to_insert,\n",
        "    )\n",
        "\n",
        "    # Execute and commit the statement to make changes in the database.\n",
        "    session.execute(stm)\n",
        "    session.commit()\n",
        "\n",
        "\n",
        "def delete_transactions():\n",
        "    \"\"\"\n",
        "    Delete operation: delete any row not present in the last snapshot\n",
        "    \"\"\"\n",
        "    # Get all ppr_raw_all transaction ids\n",
        "    raw_transaction_ids = session.query(PprRawAll.transaction_id)\n",
        "\n",
        "    # Filter all the ppt_clean_all table transactions that are not present in the ppr_raw_all table\n",
        "    # and delete them.\n",
        "    # Passing synchronize_session as argument for the delete method.\n",
        "    transactions_to_delete = session.query(PprCleanAll).filter(\n",
        "        ~PprCleanAll.transaction_id.in_(raw_transaction_ids)\n",
        "    )\n",
        "    \n",
        "    # Print transactions to delete\n",
        "    print(\"Transactions to delete:\", transactions_to_delete.count())\n",
        "\n",
        "    # Delete transactions\n",
        "    transactions_to_delete.delete(synchronize_session=False)\n",
        "\n",
        "    # Commit the session to make the changes in the database\n",
        "    session.commit()\n",
        "\n",
        "def main():\n",
        "    print(\"[Load] Start\")\n",
        "    print(\"[Load] Inserting new rows\")\n",
        "    insert_transactions()\n",
        "    print(\"[Load] Deleting rows not available in the new transformed data\")\n",
        "    delete_transactions()\n",
        "    print(\"[Load] End\")"
      ],
      "metadata": {
        "id": "Qnz1B21Fa4LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create_insights.py"
      ],
      "metadata": {
        "id": "bdrhwiSv1nnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create_insights.py\n",
        "from common.base import session\n",
        "\n",
        "# Create the view with the appropriate metrics\n",
        "query = \"\"\"\n",
        "CREATE OR REPLACE VIEW insights AS\n",
        "SELECT county,\n",
        "       count(*) AS sales_count,\n",
        "       sum(CAST(price AS int)) AS sales_total,\n",
        "       max(CAST(price AS int)) AS sales_max,\n",
        "       min(CAST(price AS int)) AS sales_min,\n",
        "       avg(CAST(price AS int))::numeric(10,2) AS sales_avg\n",
        "FROM ppr_clean_all\n",
        "GROUP BY county\n",
        "\"\"\"\n",
        "\n",
        "# Execute and commit\n",
        "session.execute(query)\n",
        "session.commit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmKOg0yItQ6u",
        "outputId": "366425d5-8d25-4c40-e1c1-fdf9da87dd71"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n",
            "<class 'str'> <class 'type'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## insights_export.py"
      ],
      "metadata": {
        "id": "i5ldT3NORqU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zet58Nxe1mwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insights_export.py\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "from common.base import session\n",
        "from common.tables import PprCleanAll\n",
        "import xlsxwriter\n",
        "\n",
        "\n",
        "# Settings\n",
        "base_path = os.path.abspath(__file__ + \"/../../\")\n",
        "ref_month = datetime.today().strftime(\"%Y-%m\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = session.execute(\"SELECT * FROM insights\").all()\n",
        "    ref_month = datetime.today().strftime(\"%Y-%m\")\n",
        "    \n",
        "    # Create the workbook\n",
        "    workbook = xlsxwriter.Workbook(\n",
        "        f\"{base_path}/insights_export/InsightsExport_202102.xlsx\"\n",
        "    )\n",
        "    \n",
        "    # Add a new worksheet\n",
        "    worksheet = workbook.add_worksheet()\n",
        "    worksheet.set_column(\"B:G\", 12)\n",
        "    \n",
        "    # Add the table with all results in the newly created worksheet\n",
        "    worksheet.add_table(\n",
        "        \"B3:E20\",\n",
        "        {\n",
        "            \"data\": data,\n",
        "            \"columns\": [\n",
        "                {\"header\": \"County\"},\n",
        "                {\"header\": \"Number of Sales 3 month\"},\n",
        "                {\"header\": \"Tot sales 3 months\"},\n",
        "                {\"header\": \"Max sales 3 months\"},\n",
        "                {\"header\": \"Min sales 3 months\"},\n",
        "                {\"header\": \"Avg sales 3 months\"},\n",
        "            ],\n",
        "        },\n",
        "    )\n",
        "    workbook.close()\n",
        "    \n",
        "    print(\"Data exported:\", f\"{base_path}/insights_export/InsightsExport_202102.xlsx\")"
      ],
      "metadata": {
        "id": "cpF2pZO5RxRE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}